"""
ChromaDB ë¬¸ì„œ ì ì¬ ìœ í‹¸ë¦¬í‹°

ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë¬¸ì„œë¥¼ ChromaDBì— ë²¡í„°í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
í”„ë¡œë•ì…˜ ì„œë¹„ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì ì¬í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

Usage:
    # Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©
    from rag.ingest import ingest_pdfs
    ingest_pdfs(["data/nlp.pdf"], persist_directory="./chroma_db")

    # DB ì´ˆê¸°í™” í›„ ìƒˆ ë°ì´í„° ì ì¬
    from rag.ingest import reset_collection, ingest_pdfs
    reset_collection(persist_directory="./chroma_db", collection_name="my_collection")
    ingest_pdfs(["data/nlp.pdf"], persist_directory="./chroma_db", collection_name="my_collection")

    # CLIì—ì„œ ì‚¬ìš©
    python -m rag.ingest data/nlp.pdf data/transformer.pdf

    # CLI: ì´ˆê¸°í™” í›„ ì ì¬
    python -m rag.ingest --reset data/nlp.pdf data/transformer.pdf
"""

import shutil
from pathlib import Path
from langchain_community.document_loaders import PDFPlumberLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from typing import List, Optional, Union

from rag.base import create_embedding_auto as create_embedding


def reset_collection(
    persist_directory: str = "./chroma_db",
    collection_name: str = "default",
):
    """
    ChromaDB ì»¬ë ‰ì…˜ì„ ì‚­ì œ(ì´ˆê¸°í™”)í•©ë‹ˆë‹¤.

    persist_directory ë‚´ì˜ íŠ¹ì • ì»¬ë ‰ì…˜ë§Œ ì‚­ì œí•˜ê±°ë‚˜,
    ë””ë ‰í† ë¦¬ ìì²´ë¥¼ ì œê±°í•˜ì—¬ ì „ì²´ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    import chromadb

    persist_path = Path(persist_directory)
    if not persist_path.exists():
        print(f"â„¹ï¸ {persist_directory} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ˆê¸°í™”í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        client = chromadb.PersistentClient(path=persist_directory)
        existing = [c.name for c in client.list_collections()]
        if collection_name in existing:
            client.delete_collection(collection_name)
            print(f"ğŸ—‘ï¸ ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì™„ë£Œ")
        else:
            print(f"â„¹ï¸ ì»¬ë ‰ì…˜ '{collection_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        remaining = client.list_collections()
        if not remaining:
            del client
            shutil.rmtree(persist_directory, ignore_errors=True)
            print(f"ğŸ—‘ï¸ ë¹ˆ DB ë””ë ‰í† ë¦¬ ì‚­ì œ: {persist_directory}")
    except Exception as e:
        print(f"âš ï¸ ì»¬ë ‰ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜, ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œë¡œ ì „í™˜: {e}")
        shutil.rmtree(persist_directory, ignore_errors=True)
        print(f"ğŸ—‘ï¸ DB ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ ì™„ë£Œ: {persist_directory}")


def ingest_pdfs(
    pdf_paths: List[str],
    persist_directory: str = "./chroma_db",
    collection_name: str = "default",
    chunk_size: int = 300,
    chunk_overlap: int = 50,
) -> Chroma:
    """
    PDF íŒŒì¼ë“¤ì„ ChromaDBì— ì ì¬í•©ë‹ˆë‹¤.

    Args:
        pdf_paths: PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        chunk_size: í…ìŠ¤íŠ¸ ë¶„í•  í¬ê¸°
        chunk_overlap: í…ìŠ¤íŠ¸ ë¶„í•  ì˜¤ë²„ë©

    Returns:
        Chroma ë²¡í„°ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤
    """
    # 1. ë¬¸ì„œ ë¡œë“œ
    docs = []
    for path in pdf_paths:
        loader = PDFPlumberLoader(path)
        loaded = loader.load()
        docs.extend(loaded)
        print(f"  ğŸ“„ {path}: {len(loaded)}í˜ì´ì§€ ë¡œë“œ")

    print(f"ğŸ“„ ì´ {len(docs)}ê°œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
    )
    split_docs = splitter.split_documents(docs)
    print(f"âœ‚ï¸ ì´ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

    # 3. ChromaDBì— ì €ì¥
    embedding = create_embedding()
    vectorstore = Chroma.from_documents(
        documents=split_docs,
        embedding=embedding,
        persist_directory=persist_directory,
        collection_name=collection_name,
    )
    print(
        f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ: {persist_directory} "
        f"(collection: {collection_name}, {len(split_docs)}ê°œ ì²­í¬)"
    )

    return vectorstore


def ingest_documents(
    file_paths: Optional[List[str]] = None,
    documents: Optional[List[Document]] = None,
    persist_directory: str = "./chroma_db",
    collection_name: str = "default",
    chunk_size: int = 300,
    chunk_overlap: int = 50,
) -> Chroma:
    """
    í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” LangChain Document ë¦¬ìŠ¤íŠ¸ë¥¼ ChromaDBì— ì ì¬í•©ë‹ˆë‹¤.

    Args:
        file_paths: í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (.txt, .md ë“±)
        documents: ì´ë¯¸ ë¡œë“œëœ LangChain Document ë¦¬ìŠ¤íŠ¸ (file_pathsì™€ íƒ 1)
        persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        chunk_size: í…ìŠ¤íŠ¸ ë¶„í•  í¬ê¸°
        chunk_overlap: í…ìŠ¤íŠ¸ ë¶„í•  ì˜¤ë²„ë©

    Returns:
        Chroma ë²¡í„°ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤

    Usage:
        # íŒŒì¼ ê²½ë¡œë¡œ ì ì¬
        ingest_documents(file_paths=["highmath12.txt", "notes.md"])

        # ì´ë¯¸ ë¡œë“œëœ Document ê°ì²´ë¡œ ì ì¬
        ingest_documents(documents=[Document(page_content="...", metadata={...})])
    """
    if file_paths is None and documents is None:
        raise ValueError("file_paths ë˜ëŠ” documents ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

    # íŒŒì¼ ê²½ë¡œê°€ ì£¼ì–´ì§„ ê²½ìš° â†’ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
    docs = []
    if file_paths:
        for path in file_paths:
            try:
                loader = TextLoader(path, encoding="utf-8")
                loaded = loader.load()
                docs.extend(loaded)
                print(f"  ğŸ“„ {path}: {len(loaded)}ê°œ ë¬¸ì„œ ë¡œë“œ")
            except Exception as e:
                print(f"  âš ï¸ {path} ë¡œë“œ ì‹¤íŒ¨: {e}")
        print(f"ğŸ“„ ì´ {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

    # ì´ë¯¸ ë¡œë“œëœ Document ê°ì²´ê°€ ì£¼ì–´ì§„ ê²½ìš°
    if documents:
        docs.extend(documents)
        print(f"ğŸ“„ Document ê°ì²´ {len(documents)}ê°œ ì¶”ê°€")

    if not docs:
        print("âš ï¸ ì ì¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # í…ìŠ¤íŠ¸ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
    )
    split_docs = splitter.split_documents(docs)
    print(f"âœ‚ï¸ ì´ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

    # ChromaDBì— ì €ì¥
    embedding = create_embedding()
    vectorstore = Chroma.from_documents(
        documents=split_docs,
        embedding=embedding,
        persist_directory=persist_directory,
        collection_name=collection_name,
    )
    print(
        f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ: {persist_directory} "
        f"(collection: {collection_name}, {len(split_docs)}ê°œ ì²­í¬)"
    )

    return vectorstore


if __name__ == "__main__":
    import sys
    import glob as globmod

    args = sys.argv[1:]
    do_reset = "--reset" in args
    if do_reset:
        args.remove("--reset")

    collection = "my_collection"
    persist_dir = "./chroma_db"

    for i, a in enumerate(args):
        if a == "--collection" and i + 1 < len(args):
            collection = args[i + 1]
            args = args[:i] + args[i + 2:]
            break
    for i, a in enumerate(args):
        if a == "--persist-dir" and i + 1 < len(args):
            persist_dir = args[i + 1]
            args = args[:i] + args[i + 2:]
            break

    expanded = []
    for a in args:
        matched = globmod.glob(a)
        expanded.extend(matched if matched else [a])

    if not expanded:
        print("Usage: python -m rag.ingest [--reset] [--collection NAME] [--persist-dir DIR] <íŒŒì¼ë“¤...>")
        print("Example: python -m rag.ingest --reset data/*.pdf")
        sys.exit(1)

    if do_reset:
        print("=" * 50)
        print("ğŸ”„ DB ì´ˆê¸°í™” ì‹œì‘")
        print("=" * 50)
        reset_collection(persist_directory=persist_dir, collection_name=collection)

    pdf_files = [f for f in expanded if f.lower().endswith(".pdf")]
    txt_files = [f for f in expanded if not f.lower().endswith(".pdf")]

    if pdf_files:
        print(f"\nğŸ“š PDF íŒŒì¼ {len(pdf_files)}ê°œ ì ì¬ ì‹œì‘...")
        ingest_pdfs(pdf_files, persist_directory=persist_dir, collection_name=collection)

    if txt_files:
        print(f"\nğŸ“š í…ìŠ¤íŠ¸ íŒŒì¼ {len(txt_files)}ê°œ ì ì¬ ì‹œì‘...")
        ingest_documents(file_paths=txt_files, persist_directory=persist_dir, collection_name=collection)
