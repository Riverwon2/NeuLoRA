# Multi-LoRA í†µí•© ì‘ì—… ì»¨í…ìŠ¤íŠ¸

## ëª©ì 

ê¸°ì¡´ ë‹¨ì¼ LLM(`Qwen/Qwen2.5-14B-Instruct`)ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ë˜ RAG íŒŒì´í”„ë¼ì¸ì—,
**ìœ ì € ì¿¼ë¦¬ì— ë”°ë¼ 4ê°œì˜ LoRA ìŠ¤íƒ€ì¼ ì¤‘ í•˜ë‚˜ë¥¼ ìë™ ì„ íƒ**í•˜ì—¬ ë‹µë³€í•˜ëŠ” êµ¬ì¡°ë¥¼ ë„ì…í•œë‹¤.

GPU ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•˜ì—¬ HuggingFace Inference APIë¥¼ í†µí•´ í˜¸ì¶œí•´ì•¼ í•œë‹¤.

## ì•„í‚¤í…ì²˜ ë³€ê²½ ìš”ì•½

```
[ë³€ê²½ ì „]
ì¿¼ë¦¬ â†’ _chain (ë‹¨ì¼ ëª¨ë¸) â†’ ë‹µë³€

[ë³€ê²½ í›„]
ì¿¼ë¦¬ â†’ embed(BGE-M3) â†’ centroid ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ â†’ style ì„ íƒ
     â†’ _chains[style] (ìŠ¤íƒ€ì¼ë³„ merged ëª¨ë¸ API) â†’ ë‹µë³€
```

## 4ê°œ LoRA ìŠ¤íƒ€ì¼

|     ìŠ¤íƒ€ì¼    |    ì„¤ëª…    | HuggingFace ë ˆí¬ |
|--------------|----------------------------|----------------------------|
|    direct    | ì§ì ‘ì  ë‹µë³€ | `RiverWon/NeuLoRA-direct` |
|   socratic   | ì†Œí¬ë¼í…ŒìŠ¤ì‹ ì§ˆë¬¸ ìœ ë„ | `RiverWon/NeuLoRA-socratic` |
|  scaffolding | ë‹¨ê³„ì  íŒíŠ¸ ì œê³µ | `RiverWon/NeuLoRA-scaffolding` |
|   feedback   | í”¼ë“œë°± ê¸°ë°˜ | `RiverWon/NeuLoRA-feedback` |

- base model: `Qwen/Qwen2.5-14B-Instruct`
- LoRA ì›ë³¸: `marimmo/multi-lora` (adapter_config: r=16, alpha=32)
- merge ë°©ì‹: safetensors ìƒ¤ë“œë³„ ìˆ˜í•™ì  merge (W_merged = W_base + B@A * alpha/r)
- ê° ë ˆí¬ëŠ” 29.6GB, 8 shards, Qwen2ForCausalLM êµ¬ì¡°

## ë¼ìš°í„°

- íŒŒì¼: `LangGraph/router_model.json` (ì¶œì²˜: `marimmo/multi-lora/router/router_model.json`)
- ë°©ì‹: hash ê¸°ë°˜ centroid classifier
- ë™ì‘: ì¿¼ë¦¬ë¥¼ BGE-M3ë¡œ ì„ë² ë”© â†’ 4ê°œ ìŠ¤íƒ€ì¼ centroidì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ â†’ ìµœëŒ€ ìœ ì‚¬ë„ ìŠ¤íƒ€ì¼ ì„ íƒ
- GPU ë¶ˆí•„ìš” (numpy ì—°ì‚°ë§Œ)

## ì™„ë£Œëœ ì‘ì—…

1. LoRA 4ê°œë¥¼ base modelì— mergeí•˜ì—¬ ê°œë³„ HuggingFace ë ˆí¬ì— ì—…ë¡œë“œ ì™„ë£Œ
2. `router_model.json`ì„ `LangGraph/` í´ë”ì— ë°°ì¹˜ ì™„ë£Œ
3. `rag/base.py` ìˆ˜ì • ì™„ë£Œ:
   - `STYLE_MODELS` ìƒìˆ˜ ì¶”ê°€
   - `create_model(self, model_name=None)` íŒŒë¼ë¯¸í„° ì¶”ê°€
   - API ë¶„ê¸°ì—ì„œ `repo_id = model_name or ANSWER_MODEL` ì ìš©
4. `rag/chroma.py` ë¶€ë¶„ ìˆ˜ì •:
   - `create_chain()` ë‚´ë¶€ì—ì„œ `self.create_model(model_name=self.model_name)` í˜¸ì¶œ
5. `LangGraph/LangGraph.py` ë¶€ë¶„ ìˆ˜ì •:
   - `import numpy as np` ì¶”ê°€
   - `LORA_ROUTER_PATH`, `STYLE_MODELS` ìƒìˆ˜ ì¶”ê°€
   - `GraphState`ì— `style` í•„ë“œ ì¶”ê°€
   - `_init_lora_router()`, `route_style()` í•¨ìˆ˜ ì¶”ê°€
   - `initialize()`ì— `_init_lora_router()` í˜¸ì¶œ ì¶”ê°€
   - `llm_answer()`ì— `route_style()` í˜¸ì¶œ ì¶”ê°€
   - `requirements.txt`ì— `numpy` ì¶”ê°€

## í˜„ì¬ ì½”ë“œì— ë‚¨ì•„ìˆëŠ” ë²„ê·¸ (ìˆ˜ì • í•„ìš”)

### ë²„ê·¸ 1: `LangGraph.py` 145~146ë²ˆ ì¤„ â€” ë³€ìˆ˜ ì„ ì–¸ ë¬¸ë²• ì˜¤ë¥˜

**í˜„ì¬ (ì˜ëª»ë¨):**
```python
_chains = Dict[str, Any] = {}
_centroids = Dict[str, list] = {}
```

**ìˆ˜ì •:**
```python
_chains: Dict[str, Any] = {}
_centroids: Dict[str, list] = {}
```

`=` â†’ `:` (íƒ€ì… íŒíŠ¸ ë¬¸ë²•)

### ë²„ê·¸ 2: `LangGraph.py` `_init_rag_chain()` â€” for ë£¨í”„ ëˆ„ë½

**í˜„ì¬ (260~280ë²ˆ ì¤„, ì˜ëª»ë¨):**
```python
def _init_rag_chain(...):
    global _retriever, _chain, _answer_model_used   # _chainì€ ì‚­ì œëœ ë³€ìˆ˜
    ...
    rag = ChromaRetrievalChain(
        ...,
        model_name = model_name,    # model_name ë¯¸ì •ì˜
    ).create_chain()
    if _retriever is None:
        _retriever = rag.retriever
    _chains[style] = rag.chain      # style ë¯¸ì •ì˜
```

**ìˆ˜ì •:**
```python
def _init_rag_chain(
    persist_directory: str = PERSIST_DIR,
    collection_name: str = COLLECTION_MAIN,
    k: int = 10,
):
    global _retriever, _chains
    _log("ğŸš€ ìŠ¤íƒ€ì¼ë³„ RAG ì²´ì¸ ìƒì„± ì‹œì‘...")

    for style, model_name in STYLE_MODELS.items():
        _log(f"  â³ {style} ì²´ì¸ ìƒì„± ì¤‘... ({model_name})")
        rag = ChromaRetrievalChain(
            persist_directory=persist_directory,
            collection_name=collection_name,
            k=k,
            model_name=model_name,
        ).create_chain()

        if _retriever is None:
            _retriever = rag.retriever
        _chains[style] = rag.chain
        _log(f"  âœ… {style} ì²´ì¸ ìƒì„± ì™„ë£Œ")

    _log(f"âœ… ì „ì²´ RAG ì²´ì¸ ìƒì„± ì™„ë£Œ: {list(_chains.keys())}")
```

### ë²„ê·¸ 3: `LangGraph.py` `llm_answer()` â€” ì—¬ì „íˆ `_chain` ì‚¬ìš©

**í˜„ì¬ (576ë²ˆ ì¤„, ì˜ëª»ë¨):**
```python
style = route_style(question)
_log(f"ğŸ¯ LoRA ìŠ¤íƒ€ì¼ ì„ íƒ: {style}")
try:
    response = _chain.invoke(...)      # _chainì€ ì‚­ì œëœ ë³€ìˆ˜
```

**ìˆ˜ì •:**
```python
style = route_style(question)
_log(f"ğŸ¯ LoRA ìŠ¤íƒ€ì¼ ì„ íƒ: {style}")
chain = _chains.get(style) or _chains.get("direct")
try:
    response = chain.invoke(
        {
            "question": question,
            "context": context,
            "chat_history": chat_history,
            "policy": policy,
        }
    )
```

ë°˜í™˜ê°’ì—ë„ `style` ì¶”ê°€:
```python
return GraphState(
    answer=response,
    style=style,
    messages=[("user", question), ("assistant", response)],
)
```

### ë²„ê·¸ 4: `rag/chroma.py` `__init__` â€” `model_name` íŒŒë¼ë¯¸í„° ëˆ„ë½

**í˜„ì¬ (31~41ë²ˆ ì¤„, ì˜ëª»ë¨):**
```python
def __init__(
    self,
    persist_directory: str = "./chroma_db",
    collection_name: str = "default",
    k: int = 10,
):                                      # model_name íŒŒë¼ë¯¸í„°ê°€ ì—†ìŒ
    super().__init__()
    self.persist_directory = persist_directory
    self.collection_name = collection_name
    self.k = k
    self.model_name = model_name        # NameError ë°œìƒ
```

**ìˆ˜ì •:**
```python
def __init__(
    self,
    persist_directory: str = "./chroma_db",
    collection_name: str = "default",
    k: int = 10,
    model_name: str | None = None,
):
    super().__init__()
    self.persist_directory = persist_directory
    self.collection_name = collection_name
    self.k = k
    self.model_name = model_name
```

## ê´€ë ¨ íŒŒì¼ ëª©ë¡

| íŒŒì¼ | ì—­í•  |
|---|---|
| `LangGraph/LangGraph.py` | ë©”ì¸ íŒŒì´í”„ë¼ì¸ (LangGraph ê¸°ë°˜) |
| `rag/base.py` | RetrievalChain ì¶”ìƒ í´ë˜ìŠ¤, create_model(), STYLE_MODELS |
| `rag/chroma.py` | ChromaDB ê¸°ë°˜ RAG ì²´ì¸ êµ¬í˜„ |
| `LangGraph/router_model.json` | LoRA ìŠ¤íƒ€ì¼ ë¼ìš°í„° centroid ë²¡í„° |
| `requirements.txt` | í”„ë¡œì íŠ¸ ì˜ì¡´ì„± |

## HuggingFace ë¦¬ì†ŒìŠ¤

| ë¦¬ì†ŒìŠ¤ | URL |
|---|---|
| LoRA ì›ë³¸ (ì–´ëŒ‘í„°) | https://huggingface.co/marimmo/multi-lora |
| ë¼ìš°í„° JSON | https://huggingface.co/marimmo/multi-lora/resolve/main/router/router_model.json |
| merged: direct | https://huggingface.co/RiverWon/NeuLoRA-direct |
| merged: socratic | https://huggingface.co/RiverWon/NeuLoRA-socratic |
| merged: scaffolding | https://huggingface.co/RiverWon/NeuLoRA-scaffolding |
| merged: feedback | https://huggingface.co/RiverWon/NeuLoRA-feedback |
